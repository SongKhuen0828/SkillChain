import * as tf from '@tensorflow/tfjs';
import { supabase } from '@/lib/supabase';

// æ˜ å°„è¡¨ï¼šæŠŠæ–‡å­—æ¨¡å¼è½¬ä¸ºæ•°å­—ï¼Œå› ä¸ºç¥ç»ç½‘ç»œåªåƒæ•°å­—
const METHOD_MAP: Record<string, number> = {
  'pomodoro': 0,
  'flowtime': 1,
  'blitz': 2,
  '52_17': 3
};
const REVERSE_MAP = ['pomodoro', 'flowtime', 'blitz', '52_17'];

// Model version key for cache invalidation
const MODEL_VERSION_KEY = 'adaptive-scheduler-model-version';
const MODEL_CACHE_KEY = 'localstorage://adaptive-scheduler-model';

// Feature flag: Disable global model loading if ai_trained_models table doesn't exist
// Set to true once the migration has been run in Supabase
const ENABLE_GLOBAL_MODEL = false;

export class AdaptiveSchedulingEngine {
  private model: tf.Sequential | null = null;
  private isTraining = false;
  private globalModelVersion: number = 0;
  private isUsingGlobalModel: boolean = false;

  private baselinePreferences: {
    preferred_study_time?: string;
    focus_span?: string;
    struggle?: string;
  } | null = null;

  /**
   * Load baseline preferences from user's onboarding quiz
   */
  async loadBaselinePreferences(userId: string) {
    try {
      const { data: preferences, error } = await supabase
        .from('ai_preferences')
        .select('preferred_study_time, focus_span, struggle')
        .eq('user_id', userId)
        .maybeSingle();
      
      if (error && error.code !== 'PGRST116') {
        // PGRST116 = not found, which is okay
        console.warn("Error loading ai_preferences (using Night Owl baseline):", error);
      }
      
      if (preferences) {
        this.baselinePreferences = preferences;
        console.log("ğŸ“Š Baseline preferences loaded:", this.baselinePreferences);
      } else {
        // Use Night Owl baseline as default
        this.baselinePreferences = {
          preferred_study_time: 'evening',
          focus_span: '25',
          struggle: 'distractions'
        };
        console.log("ğŸ“Š Using Night Owl baseline (no preferences found)");
      }
    } catch (error: any) {
      console.warn("Error loading baseline preferences (using Night Owl baseline):", error?.message || error);
      // Use Night Owl baseline as default
      this.baselinePreferences = {
        preferred_study_time: 'evening',
        focus_span: '25',
        struggle: 'distractions'
      };
    }
  }

  /**
   * Apply baseline adjustments to prediction scores
   */
  private applyBaselineAdjustment(method: string, hour: number, baseScore: number): number {
    if (!this.baselinePreferences) return baseScore;

    let adjustment = 0;

    // Adjust based on preferred study time
    // Note: onboarding uses 'routine', 'weekend', 'flexible' - we'll map them
    const studyTime = this.baselinePreferences.preferred_study_time;
    if (studyTime === 'routine' && hour >= 6 && hour <= 11) {
      // Routine learners often prefer morning
      adjustment += 0.2;
    } else if (studyTime === 'weekend' && (hour >= 9 && hour <= 17)) {
      // Weekend warriors prefer daytime hours
      adjustment += 0.2;
    } else if (studyTime === 'flexible') {
      // Flexible learners get a small boost for any hour (let TF.js handle it)
      adjustment += 0.1;
    }

    // Adjust based on focus span preference
    if (this.baselinePreferences.focus_span === 'short' && (method === 'pomodoro' || method === 'blitz')) {
      adjustment += 0.15; // +15% for short focus spans with short methods
    } else if (this.baselinePreferences.focus_span === 'long' && (method === 'flowtime' || method === '52_17')) {
      adjustment += 0.15; // +15% for long focus spans with long methods
    }

    // Adjust based on struggle type
    if (this.baselinePreferences.struggle === 'distraction' && method === 'pomodoro') {
      adjustment += 0.1; // +10% for distraction struggles with Pomodoro
    } else if (this.baselinePreferences.struggle === 'fatigue' && method === '52_17') {
      adjustment += 0.1; // +10% for fatigue struggles with 52/17
    }

    return Math.min(1.0, baseScore + adjustment); // Cap at 1.0
  }

  /**
   * 1. åˆå§‹åŒ–å¼•æ“
   * ä¼˜å…ˆä»æ•°æ®åº“åŠ è½½å…¨å±€è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æœ¬åœ°ç¼“å­˜æˆ–åˆ›å»ºåŸºçº¿æ¨¡å‹
   */
  async init(userId?: string) {
    try {
      // Load baseline preferences if userId provided
      if (userId) {
        await this.loadBaselinePreferences(userId);
      }

      // ğŸŒ ä¼˜å…ˆå°è¯•åŠ è½½å…¨å±€è®­ç»ƒå¥½çš„æ¨¡å‹ (Admin è®­ç»ƒçš„)
      // Only attempt if feature flag is enabled
      if (ENABLE_GLOBAL_MODEL) {
        const globalModelLoaded = await this.loadGlobalModel();
        
        if (globalModelLoaded) {
          console.log("ğŸŒ Adaptive Engine: Using globally trained model (v" + this.globalModelVersion + ")");
          this.isUsingGlobalModel = true;
          return;
        }
      }

      // ğŸ“¦ å¦‚æœæ²¡æœ‰å…¨å±€æ¨¡å‹ï¼Œå°è¯•åŠ è½½æœ¬åœ°ç¼“å­˜
      try {
        this.model = await tf.loadLayersModel(MODEL_CACHE_KEY) as tf.Sequential;
        console.log("ğŸ§  Adaptive Engine: Loaded local cached model.");
        this.isUsingGlobalModel = false;
      } catch (e) {
        console.log("ğŸ†• Adaptive Engine: No model found. Starting cold-start training...");
        try {
          await this.trainModel();
        } catch (trainingError) {
          console.warn("âš ï¸ Training failed, using fallback baseline model:", trainingError);
          await this.createBaselineModel();
        }
      }
    } catch (error) {
      console.error("âŒ Init error:", error);
      await this.createBaselineModel();
    }
  }

  /**
   * ä»æ•°æ®åº“åŠ è½½å…¨å±€è®­ç»ƒå¥½çš„æ¨¡å‹
   * Admin è®­ç»ƒåä¿å­˜çš„æ¨¡å‹ï¼Œæ‰€æœ‰ç”¨æˆ·å…±äº«
   */
  async loadGlobalModel(): Promise<boolean> {
    try {
      // æŸ¥è¯¢æœ€æ–°çš„ active scheduling model
      const { data: globalModel, error } = await supabase
        .from('ai_trained_models')
        .select('*')
        .eq('model_type', 'scheduling')
        .eq('is_active', true)
        .maybeSingle(); // Use maybeSingle() instead of single() to avoid 404 when no record exists

      if (error) {
        // If table doesn't exist (PGRST205) or no record found (PGRST116), that's okay - just log and return false
        // PGRST205: Table not found in schema cache
        // PGRST116: No rows returned (for .single())
        const ignorableCodes = ['PGRST205', 'PGRST116', '42P01'];
        if (ignorableCodes.includes(error.code) || 
            error.message?.includes('404') || 
            error.message?.includes('relation') || 
            error.message?.includes('does not exist') ||
            error.message?.includes('schema cache')) {
          console.log("ğŸ“­ ai_trained_models table not found or no global model exists (this is normal if table hasn't been created yet)");
          return false;
        }
        console.error("âŒ Error loading global model:", error);
        return false;
      }

      if (!globalModel) {
        console.log("ğŸ“­ No global trained model found in database");
        return false;
      }

      // æ£€æŸ¥æœ¬åœ°ç¼“å­˜çš„ç‰ˆæœ¬æ˜¯å¦æœ€æ–°
      const cachedVersion = parseInt(localStorage.getItem(MODEL_VERSION_KEY) || '0');
      
      if (cachedVersion >= globalModel.model_version && this.model) {
        console.log("âœ… Local model is up-to-date (v" + cachedVersion + ")");
        this.globalModelVersion = cachedVersion;
        return true;
      }

      // ä»æ•°æ®åº“åŠ è½½æ¨¡å‹æƒé‡
      console.log("â¬‡ï¸ Loading global model v" + globalModel.model_version + " from database...");
      
      const weights = globalModel.weights;
      const architecture = globalModel.architecture;

      if (!weights || !architecture) {
        console.warn("âš ï¸ Global model missing weights or architecture");
        return false;
      }

      // é‡å»ºæ¨¡å‹æ¶æ„
      const model = tf.sequential();
      
      // ä½¿ç”¨ä¿å­˜çš„æ¶æ„é…ç½®
      if (architecture.layers) {
        for (const layerConfig of architecture.layers) {
          if (layerConfig.type === 'dense') {
            model.add(tf.layers.dense({
              units: layerConfig.units,
              inputShape: layerConfig.inputShape,
              activation: layerConfig.activation as any,
            }));
          }
        }
      } else {
        // é»˜è®¤æ¶æ„
        model.add(tf.layers.dense({ units: 8, inputShape: [2], activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
      }

      model.compile({
        optimizer: tf.train.adam(0.01),
        loss: 'binaryCrossentropy',
        metrics: ['accuracy']
      });

      // åŠ è½½æƒé‡
      if (weights.length > 0) {
        const weightTensors = weights.map((w: any) => tf.tensor(w.data, w.shape));
        model.setWeights(weightTensors);
        // æ¸…ç†ä¸´æ—¶å¼ é‡
        weightTensors.forEach((t: tf.Tensor) => t.dispose());
      }

      // ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜
      await model.save(MODEL_CACHE_KEY);
      localStorage.setItem(MODEL_VERSION_KEY, globalModel.model_version.toString());

      this.model = model;
      this.globalModelVersion = globalModel.model_version;
      
      console.log("âœ… Global model loaded successfully (v" + globalModel.model_version + 
                  ", accuracy: " + (globalModel.accuracy * 100).toFixed(1) + "%)");
      
      return true;
    } catch (error) {
      console.error("âŒ Error loading global model:", error);
      return false;
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å…¨å±€æ¨¡å‹å¯ç”¨
   */
  async checkForModelUpdate(): Promise<boolean> {
    // Skip if global model feature is disabled
    if (!ENABLE_GLOBAL_MODEL) return false;
    
    try {
      const { data: globalModel, error } = await supabase
        .from('ai_trained_models')
        .select('model_version')
        .eq('model_type', 'scheduling')
        .eq('is_active', true)
        .maybeSingle(); // Use maybeSingle() to avoid 404 when no record exists

      if (error || !globalModel) return false;

      const cachedVersion = parseInt(localStorage.getItem(MODEL_VERSION_KEY) || '0');
      return globalModel.model_version > cachedVersion;
    } catch {
      return false;
    }
  }

  /**
   * Create a baseline model when there's insufficient data
   * Uses baseline preferences to create a simple predictive model
   */
  private async createBaselineModel() {
    try {
      const model = tf.sequential();
      model.add(tf.layers.dense({ units: 4, inputShape: [2], activation: 'relu' }));
      model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
      
      model.compile({
        optimizer: tf.train.adam(0.01),
        loss: 'binaryCrossentropy',
        metrics: ['accuracy']
      });

      // Create simple training data based on baseline preferences
      const inputs: number[][] = [];
      const labels: number[] = [];
      
      // Generate baseline data points (24 hours x 4 methods = 96 data points)
      for (let hour = 0; hour < 24; hour++) {
        for (let method = 0; method < 4; method++) {
          const normalizedHour = hour / 24;
          inputs.push([normalizedHour, method]);
          
          // Base completion rate
          let completionRate = 0.6; // 60% baseline
          
          // Apply baseline adjustments if available
          if (this.baselinePreferences) {
            const methodName = REVERSE_MAP[method];
            completionRate = this.applyBaselineAdjustment(methodName, hour, completionRate);
          }
          
          labels.push(completionRate);
        }
      }

      const xs = tf.tensor2d(inputs);
      const ys = tf.tensor2d(labels, [labels.length, 1]);

      await model.fit(xs, ys, {
        epochs: 10,
        shuffle: true,
        verbose: 0
      });

      await model.save('localstorage://adaptive-scheduler-model');
      this.model = model;
      
      xs.dispose();
      ys.dispose();
      console.log("âœ… Adaptive Engine: Baseline model created successfully.");
    } catch (error) {
      console.error("âŒ Failed to create baseline model:", error);
      // If even baseline fails, create a minimal model
      const model = tf.sequential();
      model.add(tf.layers.dense({ units: 2, inputShape: [2], activation: 'relu' }));
      model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
      model.compile({ optimizer: tf.train.adam(0.01), loss: 'binaryCrossentropy' });
      this.model = model;
    }
  }

  /**
   * 2. æ ¸å¿ƒè®­ç»ƒé€»è¾‘ (The "Adaptive" Part)
   * ä»æ•°æ®åº“æ‹‰å–ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œå®æ—¶å¾®è°ƒæ¨¡å‹
   */
  async trainModel() {
    if (this.isTraining) return;
    this.isTraining = true;

    try {
      // A. è·å–è®­ç»ƒæ•°æ® (åªå–æœ€è¿‘ 500 æ¡ï¼Œä¿è¯æ—¶æ•ˆæ€§)
      const { data: sessions, error } = await supabase
        .from('study_sessions')
        .select('started_at, method_used, completed')
        .order('started_at', { ascending: false })
        .limit(500);

      if (error) {
        console.error("Error fetching sessions for training:", error);
        this.isTraining = false;
        // Fall back to baseline model
        await this.createBaselineModel();
        return;
      }

      if (!sessions || sessions.length < 10) {
        console.warn("âš ï¸ Not enough data to train (" + (sessions?.length || 0) + " sessions). Using baseline model.");
        this.isTraining = false;
        // Use baseline model instead
        await this.createBaselineModel();
        return;
      }

    // B. æ•°æ®é¢„å¤„ç† (Feature Engineering)
    const inputs: number[][] = [];
    const labels: number[] = [];

    sessions.forEach(s => {
      const date = new Date(s.started_at);
      const hour = date.getHours(); 
      const methodCode = METHOD_MAP[s.method_used] ?? 0; 
      
      // ç‰¹å¾ 1: æ—¶é—´ (å½’ä¸€åŒ–åˆ° 0-1)
      const normalizedHour = hour / 24; 
      // ç‰¹å¾ 2: æ¨¡å¼ ID
      
      inputs.push([normalizedHour, methodCode]);
      labels.push(s.completed ? 1 : 0); // ç›®æ ‡: é¢„æµ‹æˆåŠŸç‡ (1=æˆåŠŸ, 0=å¤±è´¥)
    });

    // è½¬ä¸º Tensor å¼ é‡
    const xs = tf.tensor2d(inputs);
    const ys = tf.tensor2d(labels, [labels.length, 1]);

    // C. æ„å»ºç¥ç»ç½‘ç»œ (Neural Network Architecture)
    const model = tf.sequential();
    
    // è¾“å…¥å±‚: 2ä¸ªç‰¹å¾ (æ—¶é—´, æ¨¡å¼) -> éšè—å±‚ 8ä¸ªç¥ç»å…ƒ
    model.add(tf.layers.dense({ units: 8, inputShape: [2], activation: 'relu' }));
    // è¾“å‡ºå±‚: 1ä¸ªç¥ç»å…ƒ (æ¦‚ç‡ 0~1)
    model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));

    // ç¼–è¯‘æ¨¡å‹
    model.compile({
      optimizer: tf.train.adam(0.01), // Adam ä¼˜åŒ–å™¨
      loss: 'binaryCrossentropy',     // äºŒåˆ†ç±»æŸå¤±å‡½æ•°
      metrics: ['accuracy']
    });

      // D. è®­ç»ƒ (Training)
      console.log("ğŸ’ª Adaptive Engine: Training started...");
      await model.fit(xs, ys, {
        epochs: 30, // è®­ç»ƒ 30 è½®
        shuffle: true
      });

      // E. ä¿å­˜æ¨¡å‹
      await model.save('localstorage://adaptive-scheduler-model');
      this.model = model;
      this.isTraining = false;
      
      // å†…å­˜å›æ”¶
      xs.dispose();
      ys.dispose();
      console.log("âœ… Adaptive Engine: Training complete & Model saved.");
    } catch (error) {
      console.error("âŒ Training error:", error);
      this.isTraining = false;
      // Fall back to baseline model on error
      await this.createBaselineModel();
    }
  }

  /**
   * 3. é¢„æµ‹æœ€ä½³ç­–ç•¥ (Prediction)
   * ç»™å®šå½“å‰æ—¶é—´ï¼Œè¯„ä¼°æ¯ç§æ¨¡å¼çš„æˆåŠŸç‡ï¼Œè¿”å›æœ€é«˜çš„é‚£ä¸ª
   * å¦‚æœæ•°æ®ä¸è¶³ï¼ˆ<50 sessionsï¼‰ï¼Œä½¿ç”¨baseline preferencesè¿›è¡ŒåŠ æƒ
   */
  async predictBestMethod(userId?: string): Promise<{ method: string, confidence: number, allScores: any }> {
    try {
      if (!this.model) {
        await this.init(userId);
      }
      
      // If still no model after init, create a baseline one
      if (!this.model) {
        console.warn("âš ï¸ No model available, creating baseline model...");
        await this.createBaselineModel();
      }
      
      if (!this.model) {
        // Last resort: return default
        return { method: 'pomodoro', confidence: 0.5, allScores: { pomodoro: 0.5, flowtime: 0.5, blitz: 0.5, '52_17': 0.5 } };
      }

      // Check if we have enough data
      const { data: sessions } = await supabase
        .from('study_sessions')
        .select('id')
        .limit(50);
      
      const hasEnoughData = (sessions?.length || 0) >= 50;
    
    // Load baseline if we don't have enough data and userId is provided
    if (!hasEnoughData && userId && !this.baselinePreferences) {
      await this.loadBaselinePreferences(userId);
    }

    const currentHour = new Date().getHours();
    const currentHourNormalized = currentHour / 24;
    
    let bestMethod = 'pomodoro';
    let maxScore = -1;
    const allScores: Record<string, number> = {};

    // éå† 4 ç§æ¨¡å¼ï¼Œè®© AI ç»™æ¯ä¸€ä¸ªæ‰“åˆ†
    for (let i = 0; i < 4; i++) {
      const input = tf.tensor2d([[currentHourNormalized, i]]);
      const prediction = this.model.predict(input) as tf.Tensor;
      let score = (await prediction.data())[0]; // è·å–æˆåŠŸç‡ (0.0 - 1.0)
      
      const methodName = REVERSE_MAP[i];
      
      // Apply baseline adjustments if we don't have enough data
      if (!hasEnoughData && this.baselinePreferences) {
        score = this.applyBaselineAdjustment(methodName, currentHour, score);
      }
      
      allScores[methodName] = score;

      if (score > maxScore) {
        maxScore = score;
        bestMethod = methodName;
      }
      
      input.dispose();
      prediction.dispose();
    }

    return { method: bestMethod, confidence: maxScore, allScores };
    } catch (error) {
      console.error("âŒ Prediction error:", error);
      // Return safe defaults on error
      return { 
        method: 'pomodoro', 
        confidence: 0.5, 
        allScores: { pomodoro: 0.5, flowtime: 0.5, blitz: 0.5, '52_17': 0.5 } 
      };
    }
  }
  /**
   * Retrain model with latest data
   * Can be triggered manually or automatically when data threshold is met
   */
  async retrainModel(userId?: string): Promise<{ success: boolean; metrics?: any; error?: string }> {
    try {
      console.log('ğŸ”„ Retraining Adaptive Scheduling Model...');
      
      // Load baseline preferences if userId provided
      if (userId) {
        await this.loadBaselinePreferences(userId);
      }

      // Trigger training
      await this.trainModel();
      
      console.log('âœ… Model retraining completed');
      return { success: true };
    } catch (error: any) {
      console.error('âŒ Model retraining failed:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Get model statistics and performance metrics
   */
  async getModelStats(): Promise<{
    isLoaded: boolean;
    isTraining: boolean;
    trainingDataCount: number;
    isUsingGlobalModel: boolean;
    globalModelVersion: number;
    lastTrained?: string;
  }> {
    try {
      // Count training data
      const { count } = await supabase
        .from('study_sessions')
        .select('*', { count: 'exact', head: true });

      // Get global model info (only if feature is enabled)
      let globalModel = null;
      if (ENABLE_GLOBAL_MODEL) {
        const { data } = await supabase
          .from('ai_trained_models')
          .select('model_version, trained_at, accuracy')
          .eq('model_type', 'scheduling')
          .eq('is_active', true)
          .maybeSingle(); // Use maybeSingle() to avoid 404 when no record exists
        globalModel = data;
      }

      return {
        isLoaded: this.model !== null,
        isTraining: this.isTraining,
        trainingDataCount: count || 0,
        isUsingGlobalModel: this.isUsingGlobalModel,
        globalModelVersion: globalModel?.model_version || 0,
        lastTrained: globalModel?.trained_at,
      };
    } catch (error) {
      console.error('Error getting model stats:', error);
      return {
        isLoaded: this.model !== null,
        isTraining: this.isTraining,
        trainingDataCount: 0,
        isUsingGlobalModel: this.isUsingGlobalModel,
        globalModelVersion: this.globalModelVersion,
      };
    }
  }

  /**
   * Export current model weights (for Admin to save to database)
   */
  async exportModelWeights(): Promise<{
    weights: any[];
    architecture: any;
  } | null> {
    if (!this.model) return null;

    try {
      const weights = this.model.getWeights().map(w => ({
        data: Array.from(w.dataSync()),
        shape: w.shape,
      }));

      const architecture = {
        layers: this.model.layers.map(layer => ({
          type: 'dense',
          units: (layer as any).units,
          inputShape: layer.inputSpec?.[0]?.shape?.slice(1),
          activation: (layer as any).activation?.getClassName?.() || 'linear',
        })),
      };

      return { weights, architecture };
    } catch (error) {
      console.error('Error exporting model weights:', error);
      return null;
    }
  }
}

// å¯¼å‡ºå•ä¾‹ (Singleton)
export const schedulingEngine = new AdaptiveSchedulingEngine();
